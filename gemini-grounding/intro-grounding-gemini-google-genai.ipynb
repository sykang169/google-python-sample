{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### 목표\n",
    "\n",
    "이 튜토리얼에서는 다음 방법을 학습합니다.\n",
    "\n",
    "- Google 검색 결과를 그라운딩으로 LLM 텍스트 및 채팅 모델 응답 생성\n",
    "- 그라운딩이 설정되지 않은 LLM 응답 결과와 그라운딩 설정된 LLM 응답 비교\n",
    "- Vertex AI Search에서 데이터 저장소를 생성하고 사용하여 사용자 지정 문서 및 데이터에서 응답 그라운딩 생성\n",
    "- Vertex AI Search 결과를 그라운딩으로 LLM 텍스트 및 채팅 모델 응답 생성\n",
    "\n",
    "이 튜토리얼에서는 다음과 같은 Google Cloud AI 서비스 및 리소스를 사용합니다.\n",
    "\n",
    "- Vertex AI\n",
    "- Vertex AI Search\n",
    "\n",
    "수행 단계는 다음과 같습니다.\n",
    "\n",
    "- 다양한 예제에 대한 LLM 및 프롬프트 구성\n",
    "- Vertex AI의 생성 텍스트 및 채팅 모델에 예제 프롬프트 전송\n",
    "- 자체 데이터로 Vertex AI Search에 데이터 저장소 설정\n",
    "- 다양한 수준의 그라운딩 설정(그라운딩 설정 없음, 웹 그라운딩 설정, 데이터 저장소 그라운딩 설정)을 사용하여 예제 프롬프트 전송"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## 시작하기 전에\n",
    "\n",
    "### Google Cloud 프로젝트 설정\n",
    "\n",
    "**다음 단계는 노트북 환경에 관계없이 필수입니다.**\n",
    "\n",
    "1. [Google Cloud 프로젝트를 선택하거나 생성합니다](https://console.cloud.google.com/cloud-resource-manager). 계정을 처음 생성하면 컴퓨팅/스토리지 비용에 사용할 수 있는 $300의 무료 크레딧이 제공됩니다.\n",
    "1. [프로젝트에 대한 결제가 활성화되어 있는지 확인합니다](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "1. [Vertex AI 및 Vertex AI Search API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,discoveryengine.googleapis.com)를 활성화합니다.\n",
    "1. 이 노트북을 로컬에서 실행하는 경우 [Cloud SDK](https://cloud.google.com/sdk)를 설치해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Python용 Google Gen AI SDK 설치\n",
    "\n",
    "이 노트북을 실행하는 데 필요한 다음 패키지를 설치하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31302,
     "status": "ok",
     "timestamp": 1755607307319,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "2b4ef9b72d43",
    "outputId": "d821770b-45ba-4a9c-a2ba-38d6fa9069b8"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-genai\n",
    "%pip install --upgrade --quiet langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### Google Cloud 계정 인증\n",
    "\n",
    "이 노트북을 실행하는 경우 환경을 인증해야 합니다. 이를 위해 아래 새 셀을 실행하세요. 링크를 클릭하여 구글 클라우드 인증을 합니다. 로그인 후 나오는 key를 아래 쉘에 붙여넣습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90959,
     "status": "ok",
     "timestamp": 1755607402510,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "LA2a7ZlBD5L_",
    "outputId": "88f7723b-8c5c-4e95-bff9-e85cdc2f4298"
   },
   "outputs": [],
   "source": [
    "!gcloud auth application-default login --no-launch-browser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### Google Cloud 프로젝트 정보 설정 및 클라이언트 생성\n",
    "\n",
    "Vertex AI를 사용하려면 기존 Google Cloud 프로젝트가 있어야 하며 [Vertex AI API를 활성화](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)해야 합니다.\n",
    "\n",
    "[프로젝트 및 개발 환경 설정](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)에 대해 자세히 알아보세요.\n",
    "\n",
    "**프로젝트 ID를 모르는 경우** 다음을 시도해 보세요.\n",
    "* `gcloud config list`를 실행합니다.\n",
    "* `gcloud projects list`를 실행합니다.\n",
    "* 지원 페이지: [프로젝트 ID 찾기](https://support.google.com/googleapi/answer/7014113)를 참조하세요.\n",
    "\n",
    "Vertex AI에서 사용하는 `LOCATION` 변수를 변경할 수도 있습니다. [Vertex AI 리전](https://cloud.google.com/vertex-ai/docs/general/locations)에 대해 자세히 알아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"\"  # @param {type: \"string\"}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION =  \"us-central1\" # @param {type: \"string\"}\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### 라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from google.genai.types import (\n",
    "    ApiKeyConfig,\n",
    "    AuthConfig,\n",
    "    EnterpriseWebSearch,\n",
    "    GenerateContentConfig,\n",
    "    GenerateContentResponse,\n",
    "    GoogleMaps,\n",
    "    GoogleSearch,\n",
    "    LatLng,\n",
    "    Part,\n",
    "    Retrieval,\n",
    "    RetrievalConfig,\n",
    "    Tool,\n",
    "    ToolConfig,\n",
    "    VertexAISearch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e569c5d4a49"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cd3xp9sv77m9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "import traceback\n",
    "\n",
    "def display_grounding_data(response):\n",
    "           \"\"\"\n",
    "           (Production Version) A robust function to parse and display grounding data\n",
    "           from the native Vertex AI SDK, handling various edge cases.\n",
    "           \"\"\"\n",
    "           try:\n",
    "               # --- 1. 응답 객체에서 핵심 데이터 추출 ---\n",
    "               candidate = response.candidates[0]\n",
    "               text_content = candidate.content.parts[0].text\n",
    "               metadata = candidate.grounding_metadata\n",
    "\n",
    "               chunks = getattr(metadata, 'grounding_chunks', [])\n",
    "               supports = getattr(metadata, 'grounding_supports', [])\n",
    "               queries = getattr(metadata, 'web_search_queries', getattr(metadata, 'retrieval_queries', None)) # Changed to None default\n",
    "\n",
    "               # --- 2. 텍스트에 인용(Citation) 삽입 ---\n",
    "               final_text_parts = []\n",
    "               citation_map = {}  # 인용 번호와 chunk 인덱스 매핑\n",
    "\n",
    "               if not supports:\n",
    "                   final_text_parts.append(text_content)\n",
    "               else:\n",
    "                   text_bytes = text_content.encode('utf-8')\n",
    "                   last_index = 0\n",
    "                   # end_index 순서대로 정렬하여 순서가 섞여도 정상 처리\n",
    "                   sorted_supports = sorted(supports, key=lambda s: getattr(s.segment, 'end_index', 0))\n",
    "\n",
    "                   for support in sorted_supports:\n",
    "                       segment = getattr(support, 'segment', None)\n",
    "                       if not segment: continue\n",
    "\n",
    "                       end_index = int(getattr(segment, 'end_index', 0))\n",
    "                       indices = getattr(support, 'grounding_chunk_indices', [])\n",
    "\n",
    "                       final_text_parts.append(text_bytes[last_index:end_index].decode('utf-8'))\n",
    "                       footnote = \"\".join([f\"[{i+1}]\" for i in indices])\n",
    "                       final_text_parts.append(f\"**{footnote}**\")\n",
    "\n",
    "                       # 인용 매핑 저장\n",
    "                       for idx in indices:\n",
    "                           citation_map[idx + 1] = idx\n",
    "\n",
    "                       last_index = end_index\n",
    "\n",
    "                   final_text_parts.append(text_bytes[last_index:].decode('utf-8'))\n",
    "\n",
    "               final_text = \"\".join(final_text_parts)\n",
    "\n",
    "               # --- 3. 근거 소스(Source) 섹션 생성 ---\n",
    "               source_parts = []\n",
    "               if chunks:\n",
    "                   source_parts.append(\"\\n\\n\" + \"=\"*50)\n",
    "                   source_parts.append(\"\\n## 📚 Grounding Sources (검색 근거 자료)\\n\")\n",
    "\n",
    "                   # 각 chunk를 인용 번호와 함께 표시\n",
    "                   for i, chunk in enumerate(chunks, 1):\n",
    "                       source_parts.append(f\"\\n### [{i}] 출처 {i}\")\n",
    "\n",
    "                       # Web context 처리\n",
    "                       web_context = getattr(chunk, 'web', None)\n",
    "                       if web_context:\n",
    "                           domain = getattr(web_context, 'domain', 'Unknown')\n",
    "                           title = getattr(web_context, 'title', 'Untitled')\n",
    "                           uri = getattr(web_context, 'uri', '')\n",
    "\n",
    "                           source_parts.append(f\"\\n- **도메인**: {domain}\")\n",
    "                           source_parts.append(f\"\\n- **제목**: {title}\")\n",
    "                           if uri:\n",
    "                               # Vertex AI Search redirect URL 처리\n",
    "                               if 'vertexaisearch.cloud.google.com' in uri:\n",
    "                                   source_parts.append(f\"\\n- **링크**: [검색 결과 보기]({uri})\")\n",
    "                               else:\n",
    "                                   source_parts.append(f\"\\n- **링크**: [{domain}]({uri})\")\n",
    "\n",
    "                       # Retrieved context 처리 (파일 그라운딩 검색인 경우)\n",
    "                       retrieved_context = getattr(chunk, 'retrieved_context', None)\n",
    "                       if retrieved_context:\n",
    "                           uri = getattr(retrieved_context, 'uri', '')\n",
    "                           title = getattr(retrieved_context, 'title', 'Untitled')\n",
    "\n",
    "                           source_parts.append(f\"\\n- **문서**: {title}\")\n",
    "                           if uri:\n",
    "                               if uri.startswith(\"gs://\"):\n",
    "                                   link = uri.replace(\"gs://\", \"https://storage.googleapis.com/\", 1)\n",
    "                                   source_parts.append(f\"\\n- **저장소**: [GCS 링크]({link})\")\n",
    "                               else:\n",
    "                                   source_parts.append(f\"\\n- **경로**: {uri}\")\n",
    "\n",
    "                       source_parts.append(\"\\n\")\n",
    "\n",
    "               # --- 4. 검색 쿼리 표시 ---\n",
    "               if queries: # Added check if queries is not None\n",
    "                   source_parts.append(\"\\n\" + \"-\"*40)\n",
    "                   source_parts.append(\"\\n### 🔍 Web Search Queries (웹 검색 쿼리)\\n\")\n",
    "                   for q in queries:\n",
    "                       source_parts.append(f\"\\n- `{q}`\")\n",
    "\n",
    "               # --- 5. 최종 결과 출력 ---\n",
    "               print(\"\\n\" + \"=\"*50)\n",
    "               print(\"📝 **생성된 답변 (Citations 포함)**\")\n",
    "               print(\"=\"*50)\n",
    "               display(Markdown(final_text + \"\".join(source_parts)))\n",
    "\n",
    "               # --- 6. 디버그 정보 (선택적) ---\n",
    "               print(\"\\n\" + \"=\"*50)\n",
    "               print(\"📊 **Grounding 통계**\")\n",
    "               print(f\"- 검색된 소스 수: {len(chunks)}개\")\n",
    "               print(f\"- 인용된 구간 수: {len(supports)}개\")\n",
    "               if queries: # Added check if queries is not None\n",
    "                   print(f\"- 사용된 검색 쿼리: {len(queries)}개\")\n",
    "               print(\"=\"*50)\n",
    "\n",
    "           except Exception as e:\n",
    "               # 예상치 못한 에러 발생 시 상세 내용 출력\n",
    "               print(\"\\n--- ❌ AN UNEXPECTED ERROR OCCURRED ---\")\n",
    "               print(f\"Error: {e}\")\n",
    "               traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cf2dd17690"
   },
   "source": [
    "Vertex AI에서 Gemini 모델을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "652a8969dd5a"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e336da7161af"
   },
   "source": [
    "## 예시: Google 검색 결과를 활용한 그라운딩\n",
    "\n",
    "이 예시에서는 그라운딩이 없는 LLM 응답과 Google 검색 결과를 활용한 응답을 비교해 보겠습니다. 가장 최근의 일식에 대한 질문을 해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a28ca4abb52"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"한국에서 다음 일식은 언제인가요?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25955ce5d263"
   },
   "source": [
    "### 그라운딩 없이 텍스트 생성\n",
    "\n",
    "그라운딩 없이 LLM에 예측 요청:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 12943,
     "status": "ok",
     "timestamp": 1755607474056,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "a2e348ff93e6",
    "outputId": "d94a8218-e695-464d-e5b2-c2003d1c240b"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d7cb7cceb99"
   },
   "source": [
    "### Google 검색 결과를 그라운딩 한 텍스트 생성\n",
    "\n",
    "`Tool`에 `GoogleSearch`를 포함하는 `tools` 키워드 인수를 추가하여 Gemini가 먼저 프롬프트를 사용하여 Google 검색을 수행한 다음, 웹 검색 결과를 그라운딩하여 답변을 구성하도록 할 수 있습니다.\n",
    "\n",
    "응답의 각 `Candidate`에 대해 검색어와 [검색 진입점](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/grounding-search-entry-points)을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3287,
     "status": "ok",
     "timestamp": 1755607484109,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "1d9fb83b0ab9",
    "outputId": "518ff1fa-95b5-46cd-a4dd-ae0cdc7b7915"
   },
   "outputs": [],
   "source": [
    "google_search_tool = Tool(google_search=GoogleSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
    ")\n",
    "\n",
    "display_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d3920bb2ac0"
   },
   "source": [
    "그라운딩이 없는 응답은 LLM에서 일식에 대한 제한된 정보만 제공합니다. 반면, 웹 검색 결과에서 접지가 적용된 응답은 LLM에서 접지 요청과 함께 반환되는 웹 검색 결과에서 가장 최신 정보를 포함합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59c98ab0f5fb"
   },
   "source": [
    "### Google 검색 결과를 그라운딩으로 다중 모달 입력을 사용한 텍스트 생성\n",
    "\n",
    "Gemini는 다중 모달 입력을 사용하여 그라운딩 응답도 생성할 수 있습니다. 이 에펠탑 이미지로 시도해 보겠습니다.\n",
    "\n",
    "![파리](https://storage.googleapis.com/github-repo/generative-ai/gemini/grounding/paris.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 5038,
     "status": "ok",
     "timestamp": 1755607494759,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "5ebdda19afad",
    "outputId": "3f726858-6b2b-44d5-d66a-dd308019dbd4"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"이 위치의 현재 기온은 얼마입니까?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_uri(\n",
    "            file_uri=\"gs://github-repo/generative-ai/gemini/grounding/paris.jpg\",\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        PROMPT,\n",
    "    ],\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[google_search_tool],\n",
    "    ),\n",
    ")\n",
    "\n",
    "display_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a29c93ef3f34"
   },
   "source": [
    "## 예시: Enterprise Web Search를 이용한 Grounding\n",
    "\n",
    "Google 검색을 이용한 Grounding은 Google 검색을 사용하여 웹 검색을 수행합니다. 이 서비스의 일환으로 Google 검색은 고객 쿼리를 로깅할 수 있습니다([Google Cloud 서비스별 약관 19.k항 참조](https://cloud.google.com/terms/service-terms)). 이는 금융이나 의료와 같이 규제가 엄격한 산업의 고객의 규정 준수 요건을 충족하지 못하는 경우가 많습니다.\n",
    "\n",
    "Enterprise Web Search는 이러한 요건을 충족합니다. 고객이 Enterprise Web Search를 사용하여 웹에서 Grounding을 수행할 때, 고객 데이터를 로깅하지 않고 리전 내 VPC SC 및 ML 처리를 완벽하게 지원합니다. Enterprise Web Search Grounding은 미국 및 EU 다중 리전에서 사용할 수 있습니다.\n",
    "\n",
    "Enterprise Web Search Grounding의 요청 및 응답 형식은 Google 검색을 이용한 Grounding과 매우 유사합니다.\n",
    "\n",
    "### Gemini 모델 호환성\n",
    "\n",
    "Enterprise Web Search는 Grounding을 지원하는 모든 Gemini 2.5 모델과 호환됩니다. Gemini 2.5 Flash는 다중 모드 입력(예: 이미지, 문서, 비디오)을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11557,
     "status": "ok",
     "timestamp": 1755607510742,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "b2587492ab3f",
    "outputId": "336fcd90-8acf-40a3-a820-e7b36c4ed9c0"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}\n",
    "PROMPT = \"리오넬 메시와 크리스티아누 호날두의 경력을 비교해 보세요\"\n",
    "\n",
    "enterprise_web_search_tool = Tool(enterprise_web_search=EnterpriseWebSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[enterprise_web_search_tool]),\n",
    ")\n",
    "\n",
    "display_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmtzxL6vXRqK"
   },
   "source": [
    "Gemini 2.5 Pro를 사용하면 그라운딩은 여러 순차 검색도 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "executionInfo": {
     "elapsed": 10470,
     "status": "ok",
     "timestamp": 1755607700954,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "hhORrxki16sH",
    "outputId": "a2b8349d-0af4-465f-acd0-702924d715ae"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-pro\"  # @param {type: \"string\"}\n",
    "PROMPT = \"2024년 올림픽 100m 스프린트 우승자는 어디에서 태어났습니까?\"\n",
    "\n",
    "enterprise_web_search_tool = Tool(enterprise_web_search=EnterpriseWebSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[enterprise_web_search_tool]),\n",
    ")\n",
    "\n",
    "display_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77f0800f8762"
   },
   "source": [
    "## 예시: 사용자 지정 문서 및 데이터 그라운딩 접근\n",
    "\n",
    "이 예시에서는 그라운딩 접근이 없는 LLM 응답과 [Vertex AI Search의 검색 앱 결과](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest)를 그라운딩으로 하는 응답을 비교합니다.\n",
    "\n",
    "데이터 저장소에는 가상 은행인 Cymbal Bank의 내부 문서가 포함됩니다. 이러한 문서는 공개 인터넷에서 사용할 수 없으므로 Gemini 모델은 기본적으로 해당 문서에 대한 정보를 포함하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b308548c68b"
   },
   "source": [
    "### Vertex AI Search에서 데이터 저장소 만들기\n",
    "\n",
    "이 예시에서는 은행의 내부 문서 몇 개가 포함된 Google Cloud Storage 버킷을 사용합니다. 출장 예약 관련 문서, 이번 회계연도 전략 계획, 그리고 회사에서 제공하는 다양한 직무를 설명하는 HR 문서가 있습니다.\n",
    "\n",
    "Vertex AI Search 문서의 튜토리얼 단계에 따라 다음을 수행합니다.\n",
    "\n",
    "1. GCS 폴더 `gs://cloud-samples-data/gen-app-builder/search/cymbal-bank-employee`에서 문서를 로드하는 [비정형 데이터로 데이터 저장소를 만듭니다](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#unstructured-data).\n",
    "2. 해당 데이터 저장소에 연결된 [검색 앱을 만듭니다](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app). 데이터 저장소 내에서 인덱싱된 레코드를 검색할 수 있도록 **Enterprise Edition 기능**도 활성화해야 합니다.\n",
    "\n",
    "**참고:** 데이터 저장소는 Gemini에서 사용하는 것과 동일한 프로젝트에 있어야 합니다.\n",
    "\n",
    "이 노트북을 따라 코드를 작성할 수도 있습니다. [Vertex AI Search 데이터 저장소 및 앱 만들기](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/create_datastore_and_search.ipynb)\n",
    "\n",
    "데이터 저장소를 생성했으면 앱 ID를 얻어 아래에 입력하세요.\n",
    "\n",
    "참고: 데이터 저장소를 그라운드와 함께 사용하려면 데이터 수집이 완료될 때까지 기다려야 합니다. 자세한 내용은 [데이터 저장소 만들기](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es)를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcd767476241"
   },
   "outputs": [],
   "source": [
    "VERTEX_AI_SEARCH_PROJECT_ID = \"\"  # @param {type: \"string\"}\n",
    "VERTEX_AI_SEARCH_REGION = \"global\"  # @param {type: \"string\"}\n",
    "# Replace this with your App (Engine) ID from Vertex AI Search\n",
    "VERTEX_AI_SEARCH_APP_ID = \"\"  # @param {type: \"string\"}\n",
    "\n",
    "VERTEX_AI_SEARCH_ENGINE_NAME = f\"projects/{VERTEX_AI_SEARCH_PROJECT_ID}/locations/{VERTEX_AI_SEARCH_REGION}/collections/default_collection/engines/{VERTEX_AI_SEARCH_APP_ID}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccc156676e0a"
   },
   "source": [
    "이제 회사 문화에 대한 질문을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c1e1b1743bd"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}\n",
    "PROMPT = \"회사 문화는 어떤가요?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f365681544bb"
   },
   "source": [
    "### 그라운드 없이 텍스트 생성\n",
    "\n",
    "그라운드 없이 LLM에 답변 요청:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 9794,
     "status": "ok",
     "timestamp": 1755607734891,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "299818ae71e9",
    "outputId": "acff1b12-40fb-4271-cfea-500d96101efb"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "073f2ec42ff6"
   },
   "source": [
    "### Vertex AI 검색 결과에 그라운딩한 텍스트 생성\n",
    "\n",
    "이제 `tools` 키워드 인수에 `grounding.VertexAISearch()`라는 그라운딩 도구를 추가하여 LLM이 먼저 검색 앱 내에서 검색을 수행한 다음 관련 문서를 그라운딩으로 답변을 구성하도록 지시할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "error",
     "timestamp": 1755614647370,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "d4c5d53a37b4",
    "outputId": "1dac565d-b3f4-44da-a058-6dd9c24fb16b"
   },
   "outputs": [],
   "source": [
    "vertex_ai_search_tool = Tool(\n",
    "    retrieval=Retrieval(\n",
    "        vertex_ai_search=VertexAISearch(engine=VERTEX_AI_SEARCH_ENGINE_NAME)\n",
    "    )\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[vertex_ai_search_tool]),\n",
    ")\n",
    "\n",
    "display_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3f985c704cd"
   },
   "source": [
    "그라운딩 없는 답변에는 문의하신 회사에 대한 맥락이 전혀 없습니다. 반면, Vertex AI 검색 결과를 그라운딩으로 한 답변에는 제공된 문서의 정보와 해당 정보의 인용이 포함되어 있습니다.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ 중요 참고 사항:</b><br>\n",
    "<br>\n",
    "<b>이전 셀을 실행할 때 오류가 발생하는 경우:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;이 샘플 노트북이 Vertex AI Search의 데이터 저장소에서 작동하려면<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_data_store\">데이터 저장소</a> <b>및</b> Vertex AI에 연결된 <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app\">검색 앱</a>을 만들어야 합니다. 검색.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;데이터 저장소만 생성하는 경우, 이전 요청은 데이터 저장소에 대한 쿼리를 실행할 때 오류를 반환합니다.\n",
    "<br><br>\n",
    "<b>이전 셀을 실행할 때 빈 응답이 반환되는 경우:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;접지 기능이 있는 데이터 저장소를 사용하려면 데이터 수집이 완료될 때까지 기다려야 합니다.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;자세한 내용은 <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es\">데이터 저장소 생성</a>을 참조하세요.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54562717e2a4"
   },
   "source": [
    "## 예시: 그라운딩 채팅 응답\n",
    "\n",
    "Vertex AI에서 채팅 대화를 사용할 때 그라운딩을 사용할 수도 있습니다. 이 예시에서는 그라운딩이 없는 LLM 응답과 Google 검색 결과 및 Vertex AI 검색의 데이터 저장소를 그라운딩 하는 응답을 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "490cf1ed3399"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"Vertex AI에서 관리되는 데이터 세트란 무엇인가요?\"\n",
    "PROMPT_FOLLOWUP = \"어떤 유형의 데이터를 사용할 수 있나요?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b59783e4f1ce"
   },
   "source": [
    "### Google 검색 결과를 그라운딩으로 한 채팅 세션\n",
    "\n",
    "이제 `tools` 키워드 인수에 `GoogleSearch`라는 Tool 속성을 추가하여 채팅 모델이 먼저 프롬프트를 사용하여 Google 검색을 수행한 다음, 웹 검색 결과를 그라운딩으로 답변을 구성하도록 지시할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 16043,
     "status": "ok",
     "timestamp": 1755608149212,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "58edb2bd860f",
    "outputId": "eced830f-c676-4a38-f576-bb94e1c7c87e"
   },
   "outputs": [],
   "source": [
    "chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=GenerateContentConfig(tools=[Tool(google_search=GoogleSearch())]),\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT}\"))\n",
    "response = chat.send_message(PROMPT)\n",
    "display_grounding_data(response)\n",
    "\n",
    "display(Markdown(\"---\\n\"))\n",
    "\n",
    "display(Markdown(\"## Follow-up Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT_FOLLOWUP}\"))\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "display_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87be7f661f14"
   },
   "source": [
    "### Vertex AI 검색 결과에 그라운딩한 채팅 세션\n",
    "\n",
    "이제 `tools` 키워드 인수에 `VertexAISearch`라는 그라운딩 도구를 추가하여 채팅 세션이 먼저 사용자 지정 검색 앱 내에서 검색을 수행한 후 관련 문서를 그라운딩으로 답변을 구성하도록 지시할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fdad0c3f1f3"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"출장은 어떻게 예약하나요?\"\n",
    "PROMPT_FOLLOWUP = \"더 자세히 알려주세요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 25849,
     "status": "ok",
     "timestamp": 1755481105278,
     "user": {
      "displayName": "Seyong Kang",
      "userId": "05990600569302826575"
     },
     "user_tz": -540
    },
    "id": "1a824202a8f0",
    "outputId": "fe972714-649c-41cf-e31f-7b16287fd54c"
   },
   "outputs": [],
   "source": [
    "chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[\n",
    "            Tool(\n",
    "                retrieval=Retrieval(\n",
    "                    vertex_ai_search=VertexAISearch(engine=VERTEX_AI_SEARCH_ENGINE_NAME)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT}\"))\n",
    "response = chat.send_message(PROMPT)\n",
    "display_grounding_data(response)\n",
    "\n",
    "display(Markdown(\"---\\n\"))\n",
    "\n",
    "display(Markdown(\"## Follow-up Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT_FOLLOWUP}\"))\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "display_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## 정리\n",
    "\n",
    "이 노트북에서 사용된 리소스에 대해 Google Cloud 계정에 요금이 청구되지 않도록 하려면 다음 단계를 따르세요.\n",
    "\n",
    "1. 불필요한 Google Cloud 요금이 청구되지 않도록 [Google Cloud 콘솔](https://console.cloud.google.com/)을 사용하여 필요하지 않은 프로젝트를 삭제하세요. [프로젝트 관리 및 삭제](https://cloud.google.com/resource-manager/docs/creating-managing-projects)에 대한 Google Cloud 문서를 참조하세요.\n",
    "1. 기존 Google Cloud 프로젝트를 사용한 경우, 계정에 요금이 청구되지 않도록 생성한 리소스를 삭제하세요. 자세한 내용은 [Vertex AI Search의 데이터 저장소에서 데이터 삭제](https://cloud.google.com/generative-ai-app-builder/docs/delete-datastores) 문서를 참조한 후 데이터 저장소를 삭제하세요.\n",
    "2. Google Cloud Console에서 [Vertex AI Search API](https://console.cloud.google.com/apis/api/discoveryengine.googleapis.com) 및 [Vertex AI API](https://console.cloud.google.com/apis/api/aiplatform.googleapis.com)를 비활성화합니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb",
     "timestamp": 1755139240770
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
