{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ur8xi4C7S06n"},"outputs":[],"source":["# Copyright 2024 Google LLC\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","source":["### 목표\n","\n","이 튜토리얼에서는 다음 방법을 학습합니다.\n","\n","- Google 검색 결과를 그라운딩으로 LLM 텍스트 및 채팅 모델 응답 생성\n","- 그라운딩이 설정되지 않은 LLM 응답 결과와 그라운딩 설정된 LLM 응답 비교\n","- Vertex AI Search에서 데이터 저장소를 생성하고 사용하여 사용자 지정 문서 및 데이터에서 응답 그라운딩 생성\n","- Vertex AI Search 결과를 그라운딩으로 LLM 텍스트 및 채팅 모델 응답 생성\n","\n","이 튜토리얼에서는 다음과 같은 Google Cloud AI 서비스 및 리소스를 사용합니다.\n","\n","- Vertex AI\n","- Vertex AI Search\n","\n","수행 단계는 다음과 같습니다.\n","\n","- 다양한 예제에 대한 LLM 및 프롬프트 구성\n","- Vertex AI의 생성 텍스트 및 채팅 모델에 예제 프롬프트 전송\n","- 자체 데이터로 Vertex AI Search에 데이터 저장소 설정\n","- 다양한 수준의 그라운딩 설정(그라운딩 설정 없음, 웹 그라운딩 설정, 데이터 저장소 그라운딩 설정)을 사용하여 예제 프롬프트 전송"],"metadata":{"id":"gAJUaUWAA743"}},{"cell_type":"markdown","metadata":{"id":"BF1j6f9HApxa"},"source":["## 시작하기 전에\n","\n","### Google Cloud 프로젝트 설정\n","\n","**다음 단계는 노트북 환경에 관계없이 필수입니다.**\n","\n","1. [Google Cloud 프로젝트를 선택하거나 생성합니다](https://console.cloud.google.com/cloud-resource-manager). 계정을 처음 생성하면 컴퓨팅/스토리지 비용에 사용할 수 있는 $300의 무료 크레딧이 제공됩니다.\n","1. [프로젝트에 대한 결제가 활성화되어 있는지 확인합니다](https://cloud.google.com/billing/docs/how-to/modify-project).\n","1. [Vertex AI 및 Vertex AI Search API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,discoveryengine.googleapis.com)를 활성화합니다.\n","1. 이 노트북을 로컬에서 실행하는 경우 [Cloud SDK](https://cloud.google.com/sdk)를 설치해야 합니다."]},{"cell_type":"markdown","metadata":{"id":"i7EUnXsZhAGF"},"source":["### Python용 Google Gen AI SDK 설치\n","\n","이 노트북을 실행하는 데 필요한 다음 패키지를 설치하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2b4ef9b72d43"},"outputs":[],"source":["%pip install --upgrade --quiet google-genai\n","%pip install --upgrade --quiet langchain-google-vertexai"]},{"cell_type":"markdown","metadata":{"id":"sBCra4QMA2wR"},"source":["### Google Cloud 계정 인증\n","\n","이 노트북을 실행하는 경우 환경을 인증해야 합니다. 이를 위해 아래 새 셀을 실행하세요. 링크를 클릭하여 구글 클라우드 인증을 합니다. 로그인 후 나오는 key를 아래 쉘에 붙여넣습니다.\n"]},{"cell_type":"code","source":["!gcloud auth application-default login --no-launch-browser\n"],"metadata":{"id":"LA2a7ZlBD5L_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WReHDGG5g0XY"},"source":["### Google Cloud 프로젝트 정보 설정 및 클라이언트 생성\n","\n","Vertex AI를 사용하려면 기존 Google Cloud 프로젝트가 있어야 하며 [Vertex AI API를 활성화](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)해야 합니다.\n","\n","[프로젝트 및 개발 환경 설정](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)에 대해 자세히 알아보세요.\n","\n","**프로젝트 ID를 모르는 경우** 다음을 시도해 보세요.\n","* `gcloud config list`를 실행합니다.\n","* `gcloud projects list`를 실행합니다.\n","* 지원 페이지: [프로젝트 ID 찾기](https://support.google.com/googleapi/answer/7014113)를 참조하세요.\n","\n","Vertex AI에서 사용하는 `LOCATION` 변수를 변경할 수도 있습니다. [Vertex AI 리전](https://cloud.google.com/vertex-ai/docs/general/locations)에 대해 자세히 알아보세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oM1iC_MfAts1"},"outputs":[],"source":["import os\n","\n","PROJECT_ID = \"\"  # @param {type: \"string\"}\n","if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n","    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n","\n","LOCATION =  \"us-central1\" # @param {type: \"string\"}\n","\n","from google import genai\n","\n","client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"]},{"cell_type":"markdown","source":["### 라이브러리 가져오기"],"metadata":{"id":"Lang_ia0LL74"}},{"cell_type":"code","source":["import os\n","from langchain_google_vertexai import ChatVertexAI\n","from langchain_core.messages import HumanMessage, AIMessage # Import AIMessage\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.tools import BaseTool\n","from google.cloud.aiplatform_v1beta1.types import Tool as VertexTool\n","from google.cloud.aiplatform_v1beta1.types import EnterpriseWebSearch\n","from google.cloud.aiplatform_v1beta1.types import Retrieval, VertexAISearch as VertexAISearchConfig\n"],"metadata":{"id":"tgQzfV_BR785"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Help function for langchain"],"metadata":{"id":"kv1BvuZaKzVJ"}},{"cell_type":"code","source":["import re\n","from IPython.display import display, Markdown\n","import traceback\n","\n","def display_grounding_data_langchain(response):\n","    \"\"\"\n","    (Final Production Version) A robust function to parse and display grounding data\n","    from both native Vertex AI SDK and LangChain responses, handling various edge cases.\n","    \"\"\"\n","    try:\n","        # --- 1. 응답 객체에서 핵심 데이터 추출 ---\n","        text_content = \"\"\n","        metadata_obj = None\n","\n","        # LangChain 응답(`AIMessage`) 형식인지 확인\n","        if hasattr(response, 'response_metadata') and response.response_metadata:\n","            text_content = getattr(response, 'content', '')\n","            metadata_obj = response.response_metadata.get('grounding_metadata')\n","        # 네이티브 SDK 응답 형식인지 확인\n","        elif hasattr(response, 'candidates') and response.candidates:\n","            text_content = getattr(response.candidates[0].content.parts[0], 'text', '')\n","            metadata_obj = getattr(response.candidates[0], 'grounding_metadata', None)\n","\n","        # 메타데이터가 없는 경우, 텍스트만 출력하고 종료\n","        if not metadata_obj:\n","            print(\"⚠️ Grounding metadata not found. Displaying text only.\")\n","            display(Markdown(text_content))\n","            return\n","\n","        # --- 2. 메타데이터에서 각 구성요소 추출 (객체/사전 모두 처리) ---\n","        is_dict = isinstance(metadata_obj, dict)\n","\n","        chunks = metadata_obj.get('grounding_chunks', []) if is_dict else getattr(metadata_obj, 'grounding_chunks', [])\n","        supports = metadata_obj.get('grounding_supports', []) if is_dict else getattr(metadata_obj, 'grounding_supports', [])\n","        queries = (metadata_obj.get('retrieval_queries', []) or metadata_obj.get('web_search_queries', [])) if is_dict else (getattr(metadata_obj, 'retrieval_queries', []) or getattr(metadata_obj, 'web_search_queries', []))\n","\n","        # --- 3. 텍스트에 인용(Citation) 삽입 ---\n","        final_text_parts = []\n","        if not supports:\n","            final_text_parts.append(text_content)\n","        else:\n","            text_bytes = text_content.encode('utf-8')\n","            last_index = 0\n","\n","            # end_index 순서대로 정렬 (객체/사전 모두 처리)\n","            sorted_supports = sorted(supports, key=lambda s: int(getattr(getattr(s, 'segment', None), 'end_index', 0)) if not is_dict else int(s.get('segment', {}).get('endIndex', 0)))\n","\n","            for support in sorted_supports:\n","                is_support_dict = isinstance(support, dict)\n","                segment = support.get('segment') if is_support_dict else getattr(support, 'segment', None)\n","                if not segment: continue\n","\n","                is_segment_dict = isinstance(segment, dict)\n","                end_index = int(segment.get('endIndex', 0) if is_segment_dict else getattr(segment, 'end_index', 0))\n","                indices = support.get('groundingChunkIndices', []) if is_support_dict else getattr(support, 'grounding_chunk_indices', [])\n","\n","                final_text_parts.append(text_bytes[last_index:end_index].decode('utf-8'))\n","                footnote = \"\".join([f\"[{i+1}]\" for i in indices])\n","                final_text_parts.append(f\"**{footnote}**\")\n","                last_index = end_index\n","\n","            final_text_parts.append(text_bytes[last_index:].decode('utf-8'))\n","\n","        final_text = \"\".join(final_text_parts)\n","\n","        # --- 4. 근거 소스(Source) 섹션 생성 ---\n","        source_parts = []\n","        if chunks:\n","            source_parts.append(\"\\n\\n----\\n## 📚 Grounding Sources\")\n","\n","            unique_sources = {}\n","            for chunk in chunks:\n","                is_chunk_dict = isinstance(chunk, dict)\n","                context = chunk.get('web') or chunk.get('retrieved_context') if is_chunk_dict else getattr(chunk, 'web', getattr(chunk, 'retrieved_context', None))\n","                if not context: continue\n","\n","                is_context_dict = isinstance(context, dict)\n","                uri = context.get('uri') if is_context_dict else getattr(context, 'uri', '')\n","                if uri:\n","                    title = (context.get('title', 'Untitled Source') if is_context_dict else getattr(context, 'title', 'Untitled Source'))\n","                    unique_sources[uri] = title\n","\n","            if unique_sources:\n","                source_parts.append(\"\\n### Retrieved Chunks\")\n","                for i, (uri, title) in enumerate(unique_sources.items(), 1):\n","                    link = uri.replace(\"gs://\", \"https://storage.googleapis.com/\", 1) if uri.startswith(\"gs://\") else uri\n","                    source_parts.append(f\"\\n{i}. [{title}]({link})\")\n","\n","        if queries:\n","            query_str = \", \".join(f\"`{q}`\" for q in queries)\n","            source_parts.append(f\"\\n\\n**Search Queries:** {query_str}\")\n","\n","        # --- 5. 최종 결과 출력 ---\n","        print(\"📝 **생성된 답변 (Citations 포함)**\")\n","        display(Markdown(final_text + \"\".join(source_parts)))\n","\n","    except Exception as e:\n","        print(\"\\n--- ❌ AN UNEXPECTED ERROR OCCURRED ---\")\n","        traceback.print_exc()"],"metadata":{"id":"-4ZpbEI4K3Bb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LLM 초기화"],"metadata":{"id":"8HLHfI3baTAA"}},{"cell_type":"code","source":["MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}\n","\n","llm = ChatVertexAI(\n","    model=MODEL_ID,\n","    project=PROJECT_ID,\n","    location=LOCATION,\n",")"],"metadata":{"id":"FQA1o0MCaUun"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 예시: Google 검색 결과를 활용한 그라운딩\n","\n","이 예시에서는 그라운딩이 없는 LLM응답과 해ㅐㅎ검색 결과를 활용한 응답을 비교합니다. 가장 최근의 일식에 대한 질문을 해보겠습니다."],"metadata":{"id":"c7pqKGXWLS6e"}},{"cell_type":"code","source":["PROMPT = \"한국에서 다음 일식은 언제인가요?\""],"metadata":{"id":"CipVCpyScTJk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 그라운딩 없이 텍스트 생성\n","\n","그라운딩 없이 LLM에 예측 요청:"],"metadata":{"id":"bH-i7H2YcVOT"}},{"cell_type":"code","source":["resp = llm.invoke(\n","    input=PROMPT\n",")\n","\n","display_grounding_data_langchain( resp )"],"metadata":{"id":"4KfmchqTcUhT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","### Langchain을 사용하여 Grounding with Google Search"],"metadata":{"id":"TSt-KharSLEP"}},{"cell_type":"code","source":["# from vertexai.generative_models import Tool\n","google_search_tool = VertexTool(\n","  google_search=VertexTool.GoogleSearch()\n",")\n","\n","resp = llm.invoke(\n","    input=PROMPT,\n","    tools=[ google_search_tool ]\n",")\n","display_grounding_data_langchain( resp )\n"],"metadata":{"id":"c0PvBcW1gx17"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Langchain으로 Google 검색 결과를 그라운딩으로 다중 모달 입력을 사용한 텍스트 생성\n","\n","Langchain에서도 Gemini는 다중 모달 입력을 사용하여 그라운딩 응답도 생성할 수 있습니다. 이 경복궁 이미지로 시도해 보겠습니다.\n","\n","![서울](https://royal.khs.go.kr/resource/templete/royal/img/sub/intro/img_intro_gbg.png)"],"metadata":{"id":"PAJFW5gZRk-N"}},{"cell_type":"code","source":["# Define the multimodal prompt (Image URI + Text)\n","image_uri = \"https://royal.khs.go.kr/resource/templete/royal/img/sub/intro/img_intro_gbg.png\"\n","text_prompt = \"이 위치의 현재 기온은 얼마입니까? 현재 날짜도 알려주세요\"\n","\n","google_search_tool = VertexTool(\n","  google_search=VertexTool.GoogleSearch()  # tool_type 명시적 설정\n",")\n","\n","# Create a HumanMessage with multimodal content\n","# Content is a list of dictionaries, each with 'type' and 'source' or 'text'\n","multimodal_content = [\n","    {\n","        \"type\": \"image_url\",\n","        \"image_url\": {\"url\": image_uri}\n","    },\n","    {\n","        \"type\": \"text\",\n","        \"text\": text_prompt\n","    }\n","]\n","\n","\n","# Pass the multimodal content as the message\n","resp = llm.invoke(\n","    [HumanMessage(content=multimodal_content)],\n","    tools=google_search_tool\n","  )\n","display_grounding_data_langchain(resp)\n","\n"],"metadata":{"id":"tIqqaI1ZRF2Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 예시: 사용자 지정 문서 및 데이터 그라운딩\n","\n","이 예시에서는 그라운딩이 없는 LLM 응답과 [Vertex AI Search의 검색 앱 결과](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest)를 그라운딩하는 응답을 비교합니다.\n","\n","데이터 저장소에는 가상 은행인 Cymbal Bank의 내부 문서가 있습니다. 이러한 문서는 공개 인터넷에서 사용할 수 없으므로 Gemini 모델은 기본적으로 해당 문서에 대한 정보를 포함하지 않습니다."],"metadata":{"id":"HqsTggtYwxwr"}},{"cell_type":"markdown","source":["### Vertex AI Search에서 데이터 저장소 만들기\n","\n","이 예시에서는 은행의 내부 문서 몇 개가 포함된 Google Cloud Storage 버킷을 사용합니다. 출장 예약 관련 문서, 이번 회계연도 전략 계획, 그리고 회사에서 제공하는 다양한 직무를 설명하는 HR 문서가 있습니다.\n","\n","Vertex AI Search 문서의 튜토리얼 단계에 따라 다음을 수행합니다.\n","\n","1. GCS 폴더 `gs://cloud-samples-data/gen-app-builder/search/cymbal-bank-employee`에서 문서를 로드하는 [비정형 데이터로 데이터 저장소를 만듭니다](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#unstructured-data).\n","2. 해당 데이터 저장소에 연결된 [검색 앱을 만듭니다](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app). 데이터 저장소 내에서 인덱싱된 레코드를 검색할 수 있도록 **Enterprise Edition 기능**도 활성화해야 합니다.\n","\n","**참고:** 데이터 저장소는 Gemini에서 사용하는 것과 동일한 프로젝트에 있어야 합니다.\n","\n","이 노트북을 따라 코드를 작성할 수도 있습니다. [Vertex AI Search 데이터 저장소 및 앱 만들기](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/create_datastore_and_search.ipynb)\n","\n","데이터 저장소를 생성했으면 앱 ID를 얻어 아래에 입력하세요.\n","\n","참고: 데이터 저장소를 그라운드와 함께 사용하려면 데이터 수집이 완료될 때까지 기다려야 합니다. 자세한 내용은 [데이터 저장소 만들기](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es)를 참조하세요."],"metadata":{"id":"sOdO_kMfwz5r"}},{"cell_type":"code","source":["VERTEX_AI_SEARCH_PROJECT_ID = \"\"  # @param {type: \"string\"}\n","VERTEX_AI_SEARCH_REGION = \"global\"  # @param {type: \"string\"}\n","# Replace this with your App (Engine) ID from Vertex AI Search\n","VERTEX_AI_SEARCH_APP_ID = \"\"  # @param {type: \"string\"}\n","\n","VERTEX_AI_SEARCH_ENGINE_NAME = f\"projects/{VERTEX_AI_SEARCH_PROJECT_ID}/locations/{VERTEX_AI_SEARCH_REGION}/collections/default_collection/engines/{VERTEX_AI_SEARCH_APP_ID}\""],"metadata":{"id":"XcyVXc4ew4pi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이제 회사 문화에 대한 질문을 할 수 있습니다."],"metadata":{"id":"0PfAlx_IxLIu"}},{"cell_type":"code","source":["MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}\n","PROMPT = \"회사 문화는 어떤가요?\""],"metadata":{"id":"eGemXjhqxMDl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 그라운드 없이 텍스트 생성\n","\n","그라운드 없이 LLM에 답변 요청:"],"metadata":{"id":"qDxyIdJMxSP7"}},{"cell_type":"code","source":["resp = llm.invoke(\n","    input=PROMPT\n",")\n","\n","display_grounding_data_langchain( resp )"],"metadata":{"id":"Ouc77yVGxO8p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vertex AI 검색 결과를 그라운딩한 텍스트 생성\n","\n","이제 `tools` 키워드 인수에 `grounding.VertexAISearch()`라는 그라운딩 도구를 추가하여 LLM이 먼저 검색 앱 내에서 검색을 수행한 다음 관련 문서를 그라운딩하여 답변을 구성하도록 지시할 수 있습니다."],"metadata":{"id":"TTYIcY8-yjr0"}},{"cell_type":"code","source":["\n","# Vertex AI Search를 활용한 Grounding Tool 생성\n","vertex_ai_search_tool = VertexTool(\n","    retrieval=Retrieval(\n","        vertex_ai_search=VertexAISearchConfig(\n","            engine=VERTEX_AI_SEARCH_ENGINE_NAME\n","        )\n","    )\n",")\n","\n","# 첫 번째 질문에 대한 응답\n","response = llm.invoke(\n","    PROMPT,\n","    tools=[vertex_ai_search_tool]\n",")\n","display_grounding_data_langchain(response)"],"metadata":{"id":"NwfqUmYealp-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["그라운딩 없는 답변에는 문의하신 회사에 대한 맥락이 전혀 없습니다. 반면, Vertex AI 검색 결과를 그라운딩으로 한 답변에는 제공된 문서의 정보와 해당 정보의 인용이 포함되어 있습니다.\n","\n","<div class=\"alert alert-block alert-warning\">\n","<b>⚠️ 중요 참고 사항:</b><br>\n","<br>\n","<b>이전 셀을 실행할 때 오류가 발생하는 경우:</b><br>\n","&nbsp;&nbsp;&nbsp;&nbsp;이 샘플 노트북이 Vertex AI Search의 데이터 저장소에서 작동하려면<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_data_store\">데이터 저장소</a> <b>및</b> Vertex AI에 연결된 <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app\">검색 앱</a>을 만들어야 합니다. 검색.<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;데이터 저장소만 생성하는 경우, 이전 요청은 데이터 저장소에 대한 쿼리를 실행할 때 오류를 반환합니다.\n","<br><br>\n","<b>이전 셀을 실행할 때 빈 응답이 반환되는 경우:</b><br>\n","&nbsp;&nbsp;&nbsp;&nbsp;접지 기능이 있는 데이터 저장소를 사용하려면 데이터 수집이 완료될 때까지 기다려야 합니다.<br>\n","&nbsp;&nbsp;&nbsp;&nbsp;자세한 내용은 <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es\">데이터 저장소 생성</a>을 참조하세요.\n","</div>\n","</div>"],"metadata":{"id":"hfkml-d6zgZk"}},{"cell_type":"markdown","source":["## 예시: 그라운딩 채팅 응답\n","\n","Vertex AI에서 채팅 대화를 사용할 때 그라운딩을 사용할 수도 있습니다. 이 예시에서는 그라운딩이 없는 LLM 응답과 Google 검색 결과 및 Vertex AI 검색의 데이터 저장소를 그라운딩 하는 응답을 비교합니다."],"metadata":{"id":"RSIC22LEydmM"}},{"cell_type":"code","source":["PROMPT = \"Vertex AI에서 관리되는 데이터 세트란 무엇인가요?\"\n","PROMPT_FOLLOWUP = \"어떤 유형의 데이터를 사용할 수 있나요?\""],"metadata":{"id":"gDYJfjkKyf1z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Google 검색 결과를 그라운딩으로 한 채팅 세션\n","\n","이제 `tools` 키워드 인수에 `GoogleSearch`라는 Tool 속성을 추가하여 채팅 모델이 먼저 프롬프트를 사용하여 Google 검색을 수행한 다음, 웹 검색 결과를 그라운딩으로 답변을 구성하도록 지시할 수 있습니다."],"metadata":{"id":"A-uEDKNZzuil"}},{"cell_type":"code","source":["google_search_tool = VertexTool(\n","  google_search=VertexTool.GoogleSearch()  # tool_type 명시적 설정\n",")\n","\n","print(\"## 첫 번째 질문\")\n","print(f\"> {PROMPT}\\n\")\n","\n","# 첫 번째 질문에 대한 응답\n","response = llm.invoke(\n","    PROMPT,\n","    tools=[google_search_tool]\n",")\n","display_grounding_data_langchain(response)\n","\n","print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# 대화 이력을 유지하기 위한 메시지 리스트\n","messages = [\n","    HumanMessage(content=PROMPT),\n","    response  # AI의 첫 번째 응답\n","]\n","\n","print(\"## 후속 질문\")\n","print(f\"> {PROMPT_FOLLOWUP}\\n\")\n","\n","# 후속 질문 추가\n","messages.append(HumanMessage(content=PROMPT_FOLLOWUP))\n","\n","# 후속 질문에 대한 응답\n","followup_response = llm.invoke(\n","    messages,\n","    tools=[google_search_tool]\n",")\n","display_grounding_data_langchain(followup_response)"],"metadata":{"id":"-WCuQX-uzwug"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vertex AI 검색 결과에 그라운딩한 채팅 세션\n","\n","이제 `tools` 키워드 인수에 `VertexAISearch`라는 그라운딩 도구를 추가하여 채팅 세션이 먼저 사용자 지정 검색 앱 내에서 검색을 수행한 후 관련 문서를 그라운딩으로 답변을 구성하도록 지시할 수 있습니다."],"metadata":{"id":"skGl0x5-zIEg"}},{"cell_type":"code","source":["# 프롬프트 설정\n","PROMPT = \"회사 문화는 어떤가요?\"\n","PROMPT_FOLLOWUP = \"더 자세히 알려주세요.\""],"metadata":{"id":"Cu0cmOeH0Wlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vertex AI Search를 활용한 Grounding Tool 생성\n","vertex_ai_search_tool = VertexTool(\n","    retrieval=Retrieval(\n","        vertex_ai_search=VertexAISearchConfig(\n","            engine=VERTEX_AI_SEARCH_ENGINE_NAME\n","        )\n","    )\n",")\n","\n","\n","\n","print(\"## 첫 번째 질문\")\n","print(f\"> {PROMPT}\\n\")\n","\n","# 첫 번째 질문에 대한 응답\n","response = llm.invoke(\n","    PROMPT,\n","    tools=[vertex_ai_search_tool]\n",")\n","display_grounding_data_langchain(response)\n","\n","print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# 대화 이력을 유지하기 위한 메시지 리스트\n","messages = [\n","    HumanMessage(content=PROMPT),\n","    response  # AI의 첫 번째 응답\n","]\n","\n","print(\"## 후속 질문\")\n","print(f\"> {PROMPT_FOLLOWUP}\\n\")\n","\n","# 후속 질문 추가\n","messages.append(HumanMessage(content=PROMPT_FOLLOWUP))\n","\n","# 후속 질문에 대한 응답\n","followup_response = llm.invoke(\n","    messages,\n","    tools=[vertex_ai_search_tool]\n",")\n","display_grounding_data_langchain(followup_response)"],"metadata":{"id":"gH3Z3iAeXV6w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 예시: Enterprise Web Search를 이용한 Grounding\n","\n","Google 검색을 이용한 Grounding은 Google 검색을 사용하여 웹 검색을 수행합니다. 이 서비스의 일환으로 Google 검색은 고객 쿼리를 로깅할 수 있습니다([Google Cloud 서비스별 약관 19.k항 참조](https://cloud.google.com/terms/service-terms)). 이는 금융이나 의료와 같이 규제가 엄격한 산업의 고객의 규정 준수 요건을 충족하지 못하는 경우가 많습니다.\n","\n","Enterprise Web Search는 이러한 요건을 충족합니다. 고객이 Enterprise Web Search를 사용하여 웹에서 Grounding을 수행할 때, 고객 데이터를 로깅하지 않고 리전 내 VPC SC 및 ML 처리를 완벽하게 지원합니다. Enterprise Web Search Grounding은 미국 및 EU 다중 리전에서 사용할 수 있습니다.\n","\n","Enterprise Web Search Grounding의 요청 및 응답 형식은 Google 검색을 이용한 Grounding과 매우 유사합니다.\n","\n","이는 REST API를 사용하여 호출하는 방법입니다.\n","\n","### Gemini 모델 호환성\n","\n","Enterprise Web Search는 Grounding을 지원하는 모든 Gemini 2.5 모델과 호환됩니다. Gemini 2.5 Flash는 다중 모드 입력(예: 이미지, 문서, 비디오)을 지원합니다."],"metadata":{"id":"HMmADMFSfMQK"}},{"cell_type":"markdown","source":["### REST를 통한 Enterprise web Search를 이용한 Grounding"],"metadata":{"id":"il6EI2XR1BTQ"}},{"cell_type":"code","source":["PROMPT = \"2025년 손흥민의 팀에 대해서 알려주세요.\""],"metadata":{"id":"Ds5c2qnG3fZf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.cloud import aiplatform_v1beta1\n","from google.cloud.aiplatform_v1beta1.types import (\n","    GenerateContentRequest,\n","    Content,\n","    Part,\n","    Tool,\n","    EnterpriseWebSearch,\n",")\n","\n","\n","# 클라이언트 초기화\n","client = aiplatform_v1beta1.PredictionServiceClient(\n","    client_options={\"api_endpoint\": f\"{LOCATION}-aiplatform.googleapis.com\"}\n",")\n","\n","# Enterprise Web Search Tool 생성\n","enterprise_web_search = EnterpriseWebSearch(\n","    # 특정 도메인 제외 (선택사항)\n","    exclude_domains=[\n","        \"example-spam.com\",\n","        \"untrusted-site.com\"\n","    ]\n",")\n","\n","# Tool 객체 생성\n","tool = Tool(\n","    enterprise_web_search=enterprise_web_search\n",")\n","\n","# 요청 생성\n","endpoint = f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_ID}\"\n","\n","request = GenerateContentRequest(\n","    model=endpoint,\n","    contents=[\n","        Content(\n","            parts=[\n","                Part(text=PROMPT)\n","            ],\n","            role=\"user\"\n","        )\n","    ],\n","    tools=[tool],\n","    generation_config={\n","        \"temperature\": 0.1,\n","        \"max_output_tokens\": 2048,\n","    }\n",")\n","\n","# 응답 받기\n","\n","response = client.generate_content(request)\n","display_grounding_data_langchain(response)\n",""],"metadata":{"id":"etOx66uCrwxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TpV-iwP9qw9c"},"source":["## 정리\n","\n","이 노트북에서 사용된 리소스에 대해 Google Cloud 계정에 요금이 청구되지 않도록 하려면 다음 단계를 따르세요.\n","\n","1. 불필요한 Google Cloud 요금이 청구되지 않도록 [Google Cloud 콘솔](https://console.cloud.google.com/)을 사용하여 필요하지 않은 프로젝트를 삭제하세요. [프로젝트 관리 및 삭제](https://cloud.google.com/resource-manager/docs/creating-managing-projects)에 대한 Google Cloud 문서를 참조하세요.\n","1. 기존 Google Cloud 프로젝트를 사용한 경우, 계정에 요금이 청구되지 않도록 생성한 리소스를 삭제하세요. 자세한 내용은 [Vertex AI Search의 데이터 저장소에서 데이터 삭제](https://cloud.google.com/generative-ai-app-builder/docs/delete-datastores) 문서를 참조한 후 데이터 저장소를 삭제하세요.\n","2. Google Cloud Console에서 [Vertex AI Search API](https://console.cloud.google.com/apis/api/discoveryengine.googleapis.com) 및 [Vertex AI API](https://console.cloud.google.com/apis/api/aiplatform.googleapis.com)를 비활성화합니다."]}],"metadata":{"colab":{"provenance":[{"file_id":"1AdxrP7hoDkEVf0r4YJ_A6q8_jjU-tM3_","timestamp":1755608636079},{"file_id":"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb","timestamp":1755139240770}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}